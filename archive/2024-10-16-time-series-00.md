---
title: 'Building a probabilistic time series model: Chapter 0 â€“ Intro'
layout: post
date: 2024-10-16
categories: []
tags: []
pin: true
math: true
---
<style type="text/css">
ol ol {list-style-type: lower-alpha;}
</style>

In this post series, I want to show how to build a hierarchical time-series prediction model.
This comes from <nobr>e-commerce</nobr> data science experience where the business wants to optimize 
the amount ordered from suppliers so that it's not too small (unsatisfied demand, bad CX) but also not too high
(storage costs, including opportunity cost and possibly goods expiration).
The technical scope of the model we want to build is defined by the following required properties:

1. We want to predict future demand of different [SKUs](https://en.wikipedia.org/wiki/Stock_keeping_unit) within a certain time frame. 
2. To learn such model, we may incorporate the following kind of data:
    1. Past amounts. This is a relation over $\mathrm{SKUs} \times \mathrm{Timestamps} \times \mathbb{N}$ and it may for example represent items on invoices, logistic records or something similar.

       We do assume there are seasonalities in the data (yearly, weekly, perhaps others) as well as both short time and long time trends.
    2. Arbitrary features, which are functions of type $\mathrm{SKUs} \times \mathrm{Timestamps} \to \mathbb{R}$.
    3. Past supply (the amount available at store.) This may be seen as a function of type $\mathrm{SKUs} \times \mathrm{Timestamps} \to \mathbb{N}$.  
     
       We are predicting demand, but since we only have sales data as proxy, when there are no sales, we need to be able to distinguish when the no sales is due to no demand or no supply.

    4. A grouping of SKUs. This is a collection of disjoint sets of SKUs.
  
       SKUs within the same group are assumed to have similar behavior. This may be generalized to a rooted tree structure further on.
   5. The costs of underprediction and overprediction are understood at least roughly.
3. We desire that the model should be able to learn reasonably even in the cases where the amount of past sales data (a.) is very limited.

My big inspiration for this series is the [Prophet](https://facebook.github.io/prophet/) forecasting library,
which can readily incorporate points (a.), (b.) and (c.), but not (d.)
Because of failing to incorporate information d., Prophet fails on the requirement (3.)
I show how we can solve this using this Bayesian hierarchical modelling which in this context could be seen as form of transfer learning.
I will elaborate on (e.) later.

My main goal in this series however, is not to just present the final solution. 
Rather, I would like to explain the entire theoretical thought process that leads us there,
starting from the very basics. This allows us to make more explicit all the various assumptions
that are often buried somewhere deep and left ignored.
But studying these allows better understand its strengths and weaknesses and how to tweak the model to best suit our needs.

Tailoring a custom model for a specific domain may seem very old school
in the era of general purpose deep learning models as it requires a lot more developer labor and expertise.
However, doing it this way gives us certain advantages, including:

* a good interpretability,
* lowered requirements for the amount of training data,
* lowered need for computational resources.

But I would love the reader to have the attitude that the real treasure is the understanding we make on the way. &#x1F60A;
Nothing in this series is particularly novel, it's meant more like a compilation of already existing ideas to create something
a bit different and explain the reasoning behind the model design in more depth and detail than what may appear in an introductory course
to probability theory. For this reason, there will be multiple side-tracks for stuff I consider somewhat interesting even
when it's only marginally relevant to the final thing.
If you want to just fit some time series and make reasonable predictions, go grab Prophet and call `fit` and `predict`.
If you want to learn how to make your own Prophet and tweak and extend it to better fit your use case, read on!

I use [STAN](https://mc-stan.org/) as the modelling framework, but in principle, the same techniques could 
be implemented using different libraries, such as [PyMC](https://www.pymc.io/welcome.html).
